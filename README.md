# power-queues

## A lightweight, scalable, and high-performance queue engine for **Node.js** built on **Redis Streams** + **Lua scripts**.

The library is designed for real-world distributed systems that require high throughput, idempotent task execution, automatic recovery, and predictable performance under heavy load.

Unlike traditional Redis-based queues that rely on lists or complex abstractions, **power-queues** focuses on low-level control, atomic operations, and minimal overhead, making it ideal for high-load backends, microservices, schedulers, telemetry pipelines, and data-processing clusters.

Extends **[power-redis](https://www.npmjs.com/package/power-redis)**.

<p align="center">
	<img src="https://img.shields.io/badge/redis-streams-red?logo=redis" />
	<img src="https://img.shields.io/badge/nodejs-queue-green?logo=node.js" />
	<img src="https://img.shields.io/badge/typescript-ready-blue?logo=typescript" />
	<img src="https://img.shields.io/badge/license-MIT-lightgrey" />
	<img src="https://img.shields.io/badge/status-production-success" />
</p>

## ğŸ“š Documentation

Full documentation is available here:  
ğŸ‘‰ **https://power-queues.docs.ihor.bielchenko.com**

## ğŸ“¦ Installation

``` bash
npm install power-queues
```
OR
```bash
yarn add power-queues
```

## ğŸ§ª Basic usage

``` ts
const queue = new PowerQueues({
	stream: 'email',
	group: 'workers',
});

await queue.loadScripts(true);

await queue.addTasks('email', [
	{ payload: { type: 'welcome', userId: 42 } },
	{ payload: { type: 'hello', userId: 51 } }
]);
```

Worker:

``` ts
class EmailWorker extends PowerQueues {
	async onExecute(id, payload) {
		await sendEmail(payload);
	}
}
```

## âš–ï¸ power-queues vs Existing Solutions

|Feature               |power-queues    |BullMQ      |Bee-Queue   |Custom Streams|
|----------------------|----------------|----------- |------------|--------------|
|Bulk XADD (Lua)       |âœ… Yes          |âŒ No       |âŒ No       |Rare          |
|Idempotent workers    |âœ… Built-in     |Partial     |âŒ No       |âŒ No         |
|Stuck-task recovery   |âœ… Advanced     |Basic       |âŒ No       |Manual        |
|Heartbeats            |âœ… Yes          |Limited     |âŒ No       |Manual        |
|Retry logic           |âœ… Flexible     |Good        |Basic       |Manual        |
|DLQ                   |âœ… Native       |Basic       |âŒ No       |Manual        |
|Pure Streams          |âœ… Yes          |Partial     |âŒ No       |Yes           |
|Lua optimization      |âœ… Strong       |Minimal     |âŒ No       |Manual        |
|Throughput            |ğŸ”¥ Very high    |High        |Medium      |Depends       |
|Overhead              |Low             |Medium      |Low         |Very high     |

## ğŸš€ Key Features & Advantages

### âœ” Ultraâ€‘Fast Bulk XADD (Luaâ€‘Powered)
- Adds thousands of messages per second using optimized Lua scripts.
- Minimizes roundâ€‘trips to Redis.
- Supports batching based on:
	- number of tasks
	- number of Redis arguments (safe upper bound)
- Outperforms typical listâ€‘based queues and generic abstractions.

### âœ” Builtâ€‘in Idempotent Workers
Every task can carry an `idemKey`, guaranteeing **exactlyâ€‘once execution** even under:
- worker crashes
- network interruptions
- duplicate task submissions
- process restarts

Idempotency includes:
- Lock key
- Start key
- Done key
- TTLâ€‘managed execution lock
- Automatic release on failure
- Heartbeat mechanism
- Waiting on TTL for contended executions

This makes the engine ideal for:
- payment processing
- external API calls
- highâ€‘value jobs
- distributed pipelines

### âœ” Stuck Task Recovery (Advanced Stream Scanning)
If a worker crashes midâ€‘execution, **power-queues** automatically detects:
- abandoned tasks
- stalled locks
- unfinished start keys

The engine then recovers these tasks back to active processing safely
and efficiently.

### âœ” Highâ€‘Throughput Workers
- Batch execution support
- Parallel or sequential processing mode
- Configurable worker loop interval
- Individual and batchâ€‘level error hooks
- Safe retry flow with perâ€‘task attempt counters

### âœ” Native DLQ (Deadâ€‘Letter Queue)
When retries reach the configured limit:
- the task is moved into `${stream}:dlq`
- includes: payload, attempt count, job, timestamp, error text
- fully JSONâ€‘safe

Perfect for monitoring or later reâ€‘processing.

### âœ” Zeroâ€‘Overhead Serialization
**power-queues** uses:
- safe JSON encoding
- optional "flat" key/value task format
- predictable and optimized payload transformation

This keeps Redis memory layout clean and eliminates overhead.

### âœ” Complete Set of Lifecycle Hooks
You can extend any part of the execution flow:
- `onSelected`
- `onExecute`
- `onSuccess`
- `onError`
- `onRetry`
- `onBatchError`
- `onReady`

This allows full integration with:
- monitoring systems
- logging pipelines
- external APM tools
- domain logic

### âœ” Atomic Script Loading + NOSCRIPT Recovery
Scripts are:
- loaded once
- cached
- autoâ€‘reloaded if Redis restarts
- executed safely via SHAâ€‘based calls

Ensures resilience in failover scenarios.

### âœ” Job Progress Tracking
Optional perâ€‘job counters:
- `job:ok`
- `job:err`
- `job:ready`

Useful for UI dashboards and realâ€‘time job progress visualization.

## ğŸ§© Extensibility

**power-queues** is ideal for building:
- task schedulers
- distributed cron engines
- ETL pipelines
- telemetry processors
- notification workers
- device monitoring systems
- AI job pipelines
- high-frequency background jobs

## ğŸ§± Reliability First

Every part of the engine is designed to prevent:
- double execution
- stuck tasks
- orphan locks
- lost messages
- zombie workers
- script desynchronization

The heartbeat + TTL strategy guarantees that no task is "lost" even in
chaotic cluster environments.

## ğŸ“œ License  
MIT - free for commercial and private use.
